**Assignment 2: Single View to 3D**

Gunjan Sethi: gunjans@andrew.cmu.edu

<img src="imgs/zero.png" width="200px">

(#) Contents

 - [Fitting a Voxel Grid](#q11)  
 - [Fitting a Pointcloud](#q12) 
 - [Fitting a a Mesh](#q13)
 - [Reconstructing 3D from SingleView: Image to Voxel Grid](#q23)


(#) Exploring Loss Functions

<a name="q11">
(##) 1.1. Fitting a Voxel Grid

The goal is to define the binary cross entropy loss to help fit a 3D binary voxel 
grid.

Command: 

`python fit_data.py --type 'vox' --max-iter 25000`


| Source Voxel Grid | Ground Truth Voxel Grid | Optimized Voxel Grid |
| --- | --- | --- |
| <img src="results/q11_vg_src_before_optim.gif"> | <img src="results/q11_vg_target.gif"> | <img src="results/q11_vg_src.gif"> |


<a name="q12">
(##) 1.2. Fitting a PointCloud

The goal is to implement the chamfer loss function to help fit a 3D pointcloud. 

Command: 

`python fit_data.py --type 'point' --max-iter 12000`


| Source Pointcloud | Ground Truth Pointcloud | 
| --- | --- |
| <img src="results/0_q12_pc_src.gif"> | <img src="results/q12_pc_target.gif"> |



| 3k Iters | 6k Iters | 9k Iters | 12k Iters |
| --- | --- | --- |--- |
| <img src="results/3000_q12_pc_src.gif"> | <img src="results/6000_q12_pc_src.gif"> | <img src="results/9000_q12_pc_src.gif"> | <img src="results/12000_q12_pc_src.gif"> |


<a name="q13">
(##) 1.3. Fitting a Mesh

The goal is to define Laplacian smoothing loss to help fit a 3D mesh.

Command: 

`python3 fit_data.py --type 'mesh' --max_iter 10000`


| Source Mesh | Ground Truth Mesh | 
| --- | --- |
| <img src="results/0_q13_mesh_src.gif"> | <img src="results/q13_mesh_tgt.gif"> |


| 3k Iters | 6k Iters | 9k Iters | Optimized |
| --- | --- | --- |--- |
| <img src="results/3000_q13_mesh_src.gif"> | <img src="results/6000_q13_mesh_src.gif"> | <img src="results/9000_q13_mesh_src.gif"> | <img src="results/q13_mesh_optim.gif"> |


(#) Reconstructing 3D from Single View

The goal is to train a single view to 3D pipeline for voxels, pointclouds and meshes. 

<a name="q21">
(##) 2.1. Image to Voxel Grid (Ablations)

(###) Single ConvTranspose3D Layer

Trained for 10k iters.

`nn.ConvTranspose3d(512, 1, kernel_size=32, stride=1)`

| Images | Groudtruth Mesh | Predicted Mesh |
| -- | -- | -- |
| <img src="results/140_vox.png"> | <img src="results/q2/q21/exp4/final_140_gt_eval_vox.gif"> | <img src="results/q2/q21/exp4/final_140_pred_eval_vox.gif"> | 
| <img src="results/image_300_point.png"> | <img src="results/q2/q21/exp4/final_300_gt_eval_vox.gif"> | <img src="results/q2/q21/exp4/final_300_pred_eval_vox.gif"> | 
| <img src="results/image_400_point.png"> | <img src="results/q2/q21/exp4/final_400_gt_eval_vox.gif"> | <img src="results/q2/q21/exp4/final_400_pred_eval_vox.gif"> | 


(###) 4-Layer ConvTranspose3D Model 

This decoder model is inspired by Pix2Vox. Trained for 9k iters.

```
self.layer1 = torch.nn.Sequential(
    torch.nn.ConvTranspose3d(512, 128, kernel_size=8, stride=2, padding=1),
    torch.nn.BatchNorm3d(128),
)
self.layer2 = torch.nn.Sequential(
    torch.nn.ConvTranspose3d(128, 32, kernel_size=8, stride=2, padding=1),
    torch.nn.BatchNorm3d(32),
)
self.layer3 = torch.nn.Sequential(
    torch.nn.ConvTranspose3d(32, 8, kernel_size=4, stride=2, padding=1),
    torch.nn.BatchNorm3d(8),
)
self.layer4 = torch.nn.Sequential(
    torch.nn.ConvTranspose3d(8, 1, kernel_size=1),
)
```

| Images | Groudtruth Mesh | Predicted Mesh |
| -- | -- | -- |
| <img src="results/140_vox.png">  |        <img src="results/q2/q21/exp4/9000_140_gt_eval_vox.gif"> | <img src="results/q2/q21/exp4/9000_140_pred_eval_vox.gif"> | 
| <img src="results/image_300_point.png"> | <img src="results/q2/q21/exp4/9000_300_gt_eval_vox.gif"> | <img src="results/q2/q21/exp4/9000_300_pred_eval_vox.gif"> | 
| <img src="results/image_400_point.png"> | <img src="results/q2/q21/exp4/9000_400_gt_eval_vox.gif"> | <img src="results/q2/q21/exp4/9000_400_pred_eval_vox.gif"> | 



<!--- Markdeep & image comparison library - probably no need to change anything below -->
<style class="fallback">body{visibility:hidden;white-space:pre;font-family:monospace}</style><script src="./resources/markdeep.min.js"></script><script>window.alreadyProcessedMarkdeep||(document.body.style.visibility="visible")</script>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
<script src="./resources/jquery.event.move.js"></script>
<script src="./resources/jquery.twentytwenty.js"></script>
<link href="./resources/offcanvas.css" rel="stylesheet">
<link href="./resources/twentytwenty.css" rel="stylesheet" type="text/css" />
<script>
$(window).load(function(){$(".twentytwenty-container").twentytwenty({default_offset_pct: 0.5});});
</script>
